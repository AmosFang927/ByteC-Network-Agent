"""
ç¶²é çµæ§‹åˆ†æå™¨ - åˆ†æç¶²é çš„æ¶æ§‹ã€æ¨£å¼å’ŒåŠŸèƒ½
"""

import json
import re
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
from bs4 import BeautifulSoup
import cssutils
from urllib.parse import urljoin, urlparse
from ..config import SpiderConfig


class StructureAnalyzer:
    """ç¶²é çµæ§‹åˆ†æå™¨"""
    
    def __init__(self, playwright_client):
        """
        åˆå§‹åŒ–çµæ§‹åˆ†æå™¨
        
        Args:
            playwright_client: Playwrightå®¢æˆ¶ç«¯å¯¦ä¾‹
        """
        self.client = playwright_client
        self.config = SpiderConfig()
        self.analysis_result = {}
        
    async def analyze_page_structure(self, url: str) -> Dict[str, Any]:
        """
        åˆ†æé é¢å®Œæ•´çµæ§‹
        
        Args:
            url: é é¢URL
            
        Returns:
            Dict: åˆ†æçµæœ
        """
        try:
            print("ğŸ” é–‹å§‹åˆ†æé é¢çµæ§‹...")
            
            # ç²å–é é¢åŸºæœ¬è³‡è¨Š
            page_info = await self._get_page_info(url)
            
            # ç²å–HTMLçµæ§‹
            html_structure = await self._analyze_html_structure()
            
            # åˆ†æCSSæ¨£å¼
            css_analysis = await self._analyze_css_styles()
            
            # åˆ†æJavaScriptåŠŸèƒ½
            js_analysis = await self._analyze_javascript()
            
            # åˆ†æé é¢ä½ˆå±€
            layout_analysis = await self._analyze_layout()
            
            # åˆ†æå°èˆªçµæ§‹
            navigation_analysis = await self._analyze_navigation()
            
            # åˆ†æè¡¨å–®å…ƒç´ 
            forms_analysis = await self._analyze_forms()
            
            # åˆ†æäº’å‹•å…ƒç´ 
            interactive_analysis = await self._analyze_interactive_elements()
            
            # æ•´åˆåˆ†æçµæœ
            self.analysis_result = {
                "timestamp": datetime.now().isoformat(),
                "url": url,
                "page_info": page_info,
                "html_structure": html_structure,
                "css_analysis": css_analysis,
                "javascript_analysis": js_analysis,
                "layout_analysis": layout_analysis,
                "navigation_analysis": navigation_analysis,
                "forms_analysis": forms_analysis,
                "interactive_analysis": interactive_analysis
            }
            
            print("âœ… é é¢çµæ§‹åˆ†æå®Œæˆ")
            return self.analysis_result
            
        except Exception as e:
            print(f"âŒ åˆ†æé é¢çµæ§‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _get_page_info(self, url: str) -> Dict[str, Any]:
        """ç²å–é é¢åŸºæœ¬è³‡è¨Š"""
        try:
            print("ğŸ“„ ç²å–é é¢åŸºæœ¬è³‡è¨Š...")
            
            page_content = await self.client.get_page_content()
            soup = BeautifulSoup(page_content, 'html.parser')
            
            # ç²å–é é¢æ¨™é¡Œ
            title = soup.find('title')
            title_text = title.get_text().strip() if title else ""
            
            # ç²å–metaæ¨™ç±¤
            meta_tags = {}
            for meta in soup.find_all('meta'):
                name = meta.get('name') or meta.get('property') or meta.get('http-equiv')
                content = meta.get('content')
                if name and content:
                    meta_tags[name] = content
            
            # ç²å–viewportè¨­å®š
            viewport = soup.find('meta', attrs={'name': 'viewport'})
            viewport_content = viewport.get('content') if viewport else ""
            
            return {
                "title": title_text,
                "url": url,
                "meta_tags": meta_tags,
                "viewport": viewport_content,
                "content_length": len(page_content)
            }
            
        except Exception as e:
            print(f"âŒ ç²å–é é¢åŸºæœ¬è³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _analyze_html_structure(self) -> Dict[str, Any]:
        """åˆ†æHTMLçµæ§‹"""
        try:
            print("ğŸ—ï¸ åˆ†æHTMLçµæ§‹...")
            
            page_content = await self.client.get_page_content()
            soup = BeautifulSoup(page_content, 'html.parser')
            
            # åˆ†ææ–‡æª”çµæ§‹
            structure = {
                "doctype": "html5" if "<!DOCTYPE html>" in page_content else "other",
                "html_attributes": dict(soup.html.attrs) if soup.html else {},
                "head_elements": self._analyze_head_elements(soup),
                "body_structure": self._analyze_body_structure(soup),
                "semantic_elements": self._find_semantic_elements(soup),
                "accessibility": self._analyze_accessibility(soup)
            }
            
            return structure
            
        except Exception as e:
            print(f"âŒ åˆ†æHTMLçµæ§‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    def _analyze_head_elements(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """åˆ†æheadå…ƒç´ """
        head = soup.find('head')
        if not head:
            return {}
        
        elements = {
            "stylesheets": [],
            "scripts": [],
            "links": [],
            "meta_count": len(head.find_all('meta'))
        }
        
        # åˆ†æCSSé€£çµ
        for link in head.find_all('link', rel='stylesheet'):
            elements["stylesheets"].append({
                "href": link.get('href'),
                "media": link.get('media', 'all'),
                "integrity": link.get('integrity')
            })
        
        # åˆ†æJavaScript
        for script in head.find_all('script'):
            elements["scripts"].append({
                "src": script.get('src'),
                "type": script.get('type', 'text/javascript'),
                "async": script.has_attr('async'),
                "defer": script.has_attr('defer')
            })
        
        # åˆ†æå…¶ä»–é€£çµ
        for link in head.find_all('link'):
            if link.get('rel') != 'stylesheet':
                elements["links"].append({
                    "rel": link.get('rel'),
                    "href": link.get('href'),
                    "type": link.get('type')
                })
        
        return elements
    
    def _analyze_body_structure(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """åˆ†æbodyçµæ§‹"""
        body = soup.find('body')
        if not body:
            return {}
        
        structure = {
            "body_attributes": dict(body.attrs),
            "main_sections": [],
            "element_count": {},
            "id_classes": {
                "ids": [],
                "classes": []
            }
        }
        
        # çµ±è¨ˆå…ƒç´ æ•¸é‡
        for tag in ['div', 'section', 'article', 'aside', 'header', 'footer', 'nav', 'main']:
            count = len(body.find_all(tag))
            if count > 0:
                structure["element_count"][tag] = count
        
        # æ”¶é›†ä¸»è¦å€å¡Š
        for section in body.find_all(['section', 'main', 'article']):
            structure["main_sections"].append({
                "tag": section.name,
                "id": section.get('id'),
                "class": section.get('class'),
                "content_preview": section.get_text()[:100] + "..." if len(section.get_text()) > 100 else section.get_text()
            })
        
        # æ”¶é›†IDå’Œclass
        for element in body.find_all(True):
            if element.get('id'):
                structure["id_classes"]["ids"].append(element.get('id'))
            if element.get('class'):
                structure["id_classes"]["classes"].extend(element.get('class'))
        
        # å»é‡
        structure["id_classes"]["ids"] = list(set(structure["id_classes"]["ids"]))
        structure["id_classes"]["classes"] = list(set(structure["id_classes"]["classes"]))
        
        return structure
    
    def _find_semantic_elements(self, soup: BeautifulSoup) -> Dict[str, List]:
        """å°‹æ‰¾èªç¾©åŒ–å…ƒç´ """
        semantic_tags = ['header', 'nav', 'main', 'section', 'article', 'aside', 'footer']
        semantic_elements = {}
        
        for tag in semantic_tags:
            elements = soup.find_all(tag)
            semantic_elements[tag] = [
                {
                    "id": elem.get('id'),
                    "class": elem.get('class'),
                    "content_preview": elem.get_text()[:50] + "..." if len(elem.get_text()) > 50 else elem.get_text()
                }
                for elem in elements
            ]
        
        return semantic_elements
    
    def _analyze_accessibility(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """åˆ†æç„¡éšœç¤™æ€§"""
        accessibility = {
            "alt_texts": 0,
            "missing_alt": 0,
            "aria_labels": 0,
            "heading_structure": [],
            "landmarks": []
        }
        
        # æª¢æŸ¥åœ–ç‰‡altå±¬æ€§
        images = soup.find_all('img')
        for img in images:
            if img.get('alt'):
                accessibility["alt_texts"] += 1
            else:
                accessibility["missing_alt"] += 1
        
        # æª¢æŸ¥ARIAæ¨™ç±¤
        aria_elements = soup.find_all(True, attrs=lambda x: x and any(key.startswith('aria-') for key in x.keys()))
        accessibility["aria_labels"] = len(aria_elements)
        
        # æª¢æŸ¥æ¨™é¡Œçµæ§‹
        for i in range(1, 7):
            headings = soup.find_all(f'h{i}')
            if headings:
                accessibility["heading_structure"].append({
                    f"h{i}": len(headings),
                    "texts": [h.get_text().strip()[:50] for h in headings[:3]]
                })
        
        # æª¢æŸ¥landmarkå…ƒç´ 
        landmarks = soup.find_all(['header', 'nav', 'main', 'aside', 'footer'])
        accessibility["landmarks"] = [elem.name for elem in landmarks]
        
        return accessibility
    
    async def _analyze_css_styles(self) -> Dict[str, Any]:
        """åˆ†æCSSæ¨£å¼"""
        try:
            print("ğŸ¨ åˆ†æCSSæ¨£å¼...")
            
            # ç²å–CSSè³‡æº
            css_links = await self._get_css_resources()
            
            # åˆ†æå…§è¯æ¨£å¼
            inline_styles = await self._analyze_inline_styles()
            
            # åˆ†æCSSè®Šæ•¸å’Œä¸»é¡Œ
            css_variables = await self._extract_css_variables()
            
            # åˆ†æéŸ¿æ‡‰å¼è¨­è¨ˆ
            responsive_design = await self._analyze_responsive_design()
            
            return {
                "external_stylesheets": css_links,
                "inline_styles": inline_styles,
                "css_variables": css_variables,
                "responsive_design": responsive_design
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æCSSæ¨£å¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _get_css_resources(self) -> List[Dict]:
        """ç²å–CSSè³‡æº"""
        try:
            # åŸ·è¡ŒJavaScriptç²å–æ‰€æœ‰CSSé€£çµ
            script = """
            const links = Array.from(document.querySelectorAll('link[rel="stylesheet"]'));
            return links.map(link => ({
                href: link.href,
                media: link.media || 'all',
                disabled: link.disabled
            }));
            """
            
            css_links = await self.client._mcp_evaluate(script)
            return css_links or []
            
        except Exception as e:
            print(f"âŒ ç²å–CSSè³‡æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    async def _analyze_inline_styles(self) -> Dict[str, Any]:
        """åˆ†æå…§è¯æ¨£å¼"""
        try:
            page_content = await self.client.get_page_content()
            soup = BeautifulSoup(page_content, 'html.parser')
            
            # æ”¶é›†styleæ¨™ç±¤
            style_tags = soup.find_all('style')
            style_content = []
            
            for style in style_tags:
                style_content.append(style.get_text())
            
            # æ”¶é›†å…§è¯æ¨£å¼
            inline_styles = []
            for element in soup.find_all(True, style=True):
                inline_styles.append({
                    "tag": element.name,
                    "style": element.get('style'),
                    "id": element.get('id'),
                    "class": element.get('class')
                })
            
            return {
                "style_tags_count": len(style_tags),
                "style_content": style_content,
                "inline_styles_count": len(inline_styles),
                "inline_styles": inline_styles[:10]  # é™åˆ¶æ•¸é‡
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æå…§è¯æ¨£å¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _extract_css_variables(self) -> Dict[str, Any]:
        """æå–CSSè®Šæ•¸"""
        try:
            script = """
            const rootStyles = getComputedStyle(document.documentElement);
            const variables = {};
            
            // ç²å–CSSè‡ªå®šç¾©å±¬æ€§
            for (let i = 0; i < rootStyles.length; i++) {
                const prop = rootStyles[i];
                if (prop.startsWith('--')) {
                    variables[prop] = rootStyles.getPropertyValue(prop).trim();
                }
            }
            
            return variables;
            """
            
            css_variables = await self.client._mcp_evaluate(script)
            return css_variables or {}
            
        except Exception as e:
            print(f"âŒ æå–CSSè®Šæ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _analyze_responsive_design(self) -> Dict[str, Any]:
        """åˆ†æéŸ¿æ‡‰å¼è¨­è¨ˆ"""
        try:
            page_content = await self.client.get_page_content()
            
            # æª¢æŸ¥viewport meta tag
            has_viewport = 'viewport' in page_content
            
            # æª¢æŸ¥åª’é«”æŸ¥è©¢
            media_queries = re.findall(r'@media[^{]+{[^}]*}', page_content, re.IGNORECASE)
            
            # æª¢æŸ¥éŸ¿æ‡‰å¼é¡åˆ¥
            responsive_classes = []
            responsive_patterns = [
                r'\.col-\w+',
                r'\.row',
                r'\.container',
                r'\.responsive',
                r'\.mobile',
                r'\.tablet',
                r'\.desktop'
            ]
            
            for pattern in responsive_patterns:
                matches = re.findall(pattern, page_content, re.IGNORECASE)
                responsive_classes.extend(matches)
            
            return {
                "has_viewport_meta": has_viewport,
                "media_queries_count": len(media_queries),
                "responsive_classes": list(set(responsive_classes))
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æéŸ¿æ‡‰å¼è¨­è¨ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _analyze_javascript(self) -> Dict[str, Any]:
        """åˆ†æJavaScriptåŠŸèƒ½"""
        try:
            print("âš¡ åˆ†æJavaScriptåŠŸèƒ½...")
            
            # ç²å–JavaScriptè³‡æº
            js_resources = await self._get_js_resources()
            
            # åˆ†æäº‹ä»¶ç›£è½å™¨
            event_listeners = await self._analyze_event_listeners()
            
            # æª¢æŸ¥æ¡†æ¶å’Œåº«
            frameworks = await self._detect_frameworks()
            
            return {
                "js_resources": js_resources,
                "event_listeners": event_listeners,
                "frameworks": frameworks
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æJavaScriptæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _get_js_resources(self) -> List[Dict]:
        """ç²å–JavaScriptè³‡æº"""
        try:
            script = """
            const scripts = Array.from(document.querySelectorAll('script'));
            return scripts.map(script => ({
                src: script.src || null,
                type: script.type || 'text/javascript',
                async: script.async,
                defer: script.defer,
                hasContent: script.innerHTML.length > 0
            }));
            """
            
            js_resources = await self.client._mcp_evaluate(script)
            return js_resources or []
            
        except Exception as e:
            print(f"âŒ ç²å–JavaScriptè³‡æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    async def _analyze_event_listeners(self) -> Dict[str, Any]:
        """åˆ†æäº‹ä»¶ç›£è½å™¨"""
        try:
            script = """
            const events = {};
            const elements = document.querySelectorAll('*');
            
            elements.forEach(element => {
                const attributes = Array.from(element.attributes);
                attributes.forEach(attr => {
                    if (attr.name.startsWith('on')) {
                        const eventType = attr.name.substring(2);
                        if (!events[eventType]) {
                            events[eventType] = 0;
                        }
                        events[eventType]++;
                    }
                });
            });
            
            return events;
            """
            
            event_listeners = await self.client._mcp_evaluate(script)
            return event_listeners or {}
            
        except Exception as e:
            print(f"âŒ åˆ†æäº‹ä»¶ç›£è½å™¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _detect_frameworks(self) -> List[str]:
        """æª¢æ¸¬JavaScriptæ¡†æ¶"""
        try:
            script = """
            const frameworks = [];
            
            // æª¢æ¸¬å¸¸è¦‹æ¡†æ¶
            if (typeof React !== 'undefined') frameworks.push('React');
            if (typeof Vue !== 'undefined') frameworks.push('Vue');
            if (typeof Angular !== 'undefined') frameworks.push('Angular');
            if (typeof jQuery !== 'undefined') frameworks.push('jQuery');
            if (typeof $ !== 'undefined') frameworks.push('jQuery-like');
            if (typeof bootstrap !== 'undefined') frameworks.push('Bootstrap');
            
            return frameworks;
            """
            
            frameworks = await self.client._mcp_evaluate(script)
            return frameworks or []
            
        except Exception as e:
            print(f"âŒ æª¢æ¸¬æ¡†æ¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    async def _analyze_layout(self) -> Dict[str, Any]:
        """åˆ†æé é¢ä½ˆå±€"""
        try:
            print("ğŸ“ åˆ†æé é¢ä½ˆå±€...")
            
            script = """
            const layout = {
                viewport: {
                    width: window.innerWidth,
                    height: window.innerHeight
                },
                scroll: {
                    width: document.documentElement.scrollWidth,
                    height: document.documentElement.scrollHeight
                },
                sections: []
            };
            
            // åˆ†æä¸»è¦å€å¡Š
            const sections = document.querySelectorAll('header, nav, main, section, aside, footer, .container, .wrapper');
            sections.forEach(section => {
                const rect = section.getBoundingClientRect();
                layout.sections.push({
                    tag: section.tagName.toLowerCase(),
                    id: section.id || null,
                    className: section.className || null,
                    position: {
                        x: rect.x,
                        y: rect.y,
                        width: rect.width,
                        height: rect.height
                    }
                });
            });
            
            return layout;
            """
            
            layout = await self.client._mcp_evaluate(script)
            return layout or {}
            
        except Exception as e:
            print(f"âŒ åˆ†æé é¢ä½ˆå±€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _analyze_navigation(self) -> Dict[str, Any]:
        """åˆ†æå°èˆªçµæ§‹"""
        try:
            print("ğŸ§­ åˆ†æå°èˆªçµæ§‹...")
            
            page_content = await self.client.get_page_content()
            soup = BeautifulSoup(page_content, 'html.parser')
            
            navigation = {
                "nav_elements": [],
                "menu_items": [],
                "breadcrumbs": [],
                "links": []
            }
            
            # åˆ†ænavå…ƒç´ 
            nav_elements = soup.find_all('nav')
            for nav in nav_elements:
                navigation["nav_elements"].append({
                    "id": nav.get('id'),
                    "class": nav.get('class'),
                    "links_count": len(nav.find_all('a'))
                })
            
            # åˆ†æé¸å–®é …ç›®
            menu_selectors = ['ul.menu', '.navigation', '.nav-menu', '.main-menu']
            for selector in menu_selectors:
                menus = soup.select(selector)
                for menu in menus:
                    items = menu.find_all('li')
                    navigation["menu_items"].extend([
                        item.get_text().strip() for item in items if item.get_text().strip()
                    ])
            
            # åˆ†æéºµåŒ…å±‘
            breadcrumb_selectors = ['.breadcrumb', '.breadcrumbs', '[aria-label*="breadcrumb"]']
            for selector in breadcrumb_selectors:
                breadcrumbs = soup.select(selector)
                for breadcrumb in breadcrumbs:
                    items = breadcrumb.find_all(['li', 'a', 'span'])
                    navigation["breadcrumbs"].extend([
                        item.get_text().strip() for item in items if item.get_text().strip()
                    ])
            
            # æ”¶é›†æ‰€æœ‰é€£çµ
            links = soup.find_all('a', href=True)
            navigation["links"] = [
                {
                    "text": link.get_text().strip(),
                    "href": link.get('href'),
                    "title": link.get('title')
                }
                for link in links[:20]  # é™åˆ¶æ•¸é‡
            ]
            
            return navigation
            
        except Exception as e:
            print(f"âŒ åˆ†æå°èˆªçµæ§‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _analyze_forms(self) -> Dict[str, Any]:
        """åˆ†æè¡¨å–®å…ƒç´ """
        try:
            print("ğŸ“ åˆ†æè¡¨å–®å…ƒç´ ...")
            
            page_content = await self.client.get_page_content()
            soup = BeautifulSoup(page_content, 'html.parser')
            
            forms_analysis = {
                "forms_count": 0,
                "forms": [],
                "input_types": {},
                "validation": []
            }
            
            forms = soup.find_all('form')
            forms_analysis["forms_count"] = len(forms)
            
            for form in forms:
                form_data = {
                    "id": form.get('id'),
                    "class": form.get('class'),
                    "method": form.get('method', 'GET'),
                    "action": form.get('action'),
                    "inputs": []
                }
                
                # åˆ†æè¼¸å…¥æ¬„ä½
                inputs = form.find_all(['input', 'textarea', 'select'])
                for inp in inputs:
                    input_type = inp.get('type', 'text')
                    
                    # çµ±è¨ˆè¼¸å…¥é¡å‹
                    if input_type not in forms_analysis["input_types"]:
                        forms_analysis["input_types"][input_type] = 0
                    forms_analysis["input_types"][input_type] += 1
                    
                    form_data["inputs"].append({
                        "tag": inp.name,
                        "type": input_type,
                        "name": inp.get('name'),
                        "id": inp.get('id'),
                        "required": inp.has_attr('required'),
                        "placeholder": inp.get('placeholder')
                    })
                
                forms_analysis["forms"].append(form_data)
            
            return forms_analysis
            
        except Exception as e:
            print(f"âŒ åˆ†æè¡¨å–®å…ƒç´ æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {}
    
    async def _analyze_interactive_elements(self) -> Dict[str, Any]:
        """åˆ†æäº’å‹•å…ƒç´ """
        try:
            print("ğŸ–±ï¸ åˆ†æäº’å‹•å…ƒç´ ...")
            
            script = """
            const interactive = {
                buttons: 0,
                clickable_elements: 0,
                hover_effects: 0,
                modals: 0,
                dropdowns: 0
            };
            
            // çµ±è¨ˆæŒ‰éˆ•
            interactive.buttons = document.querySelectorAll('button, input[type="button"], input[type="submit"]').length;
            
            // çµ±è¨ˆå¯é»æ“Šå…ƒç´ 
            const clickable = document.querySelectorAll('[onclick], [data-toggle], [data-target], .clickable, .btn');
            interactive.clickable_elements = clickable.length;
            
            // æª¢æŸ¥æ¨¡æ…‹æ¡†
            interactive.modals = document.querySelectorAll('.modal, .popup, [data-modal]').length;
            
            // æª¢æŸ¥ä¸‹æ‹‰é¸å–®
            interactive.dropdowns = document.querySelectorAll('.dropdown, .select, select').length;
            
            return interactive;
            """
            
            interactive = await self.client._mcp_evaluate(script)
            return interactive or {}
            
        except Exception as e:
            print(f"âŒ åˆ†æäº’å‹•å…ƒç´ æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {} 
#!/usr/bin/env python3
"""
PostBackæ•°æ®åº“è®¿é—®å±‚
è¿æ¥åˆ°ç°æœ‰çš„ bytec-network PostgreSQL æ•°æ®åº“
"""

import asyncio
import asyncpg
import pandas as pd
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
from dataclasses import dataclass
from decimal import Decimal

# å°å…¥æ˜ å°„ç®¡ç†å™¨
from .mapping_manager import MappingManager

logger = logging.getLogger(__name__)

@dataclass
class ConversionRecord:
    """è½¬åŒ–è®°å½•æ•°æ®ç±»"""
    id: int
    tenant_id: int
    conversion_id: str
    offer_id: Optional[str]
    offer_name: Optional[str]
    datetime_conversion: Optional[datetime]
    order_id: Optional[str]
    usd_sale_amount: Optional[Decimal]
    usd_payout: Optional[Decimal]
    aff_sub: Optional[str]
    aff_sub2: Optional[str]
    aff_sub3: Optional[str]
    aff_sub4: Optional[str]
    status: Optional[str]
    received_at: datetime
    tenant_name: str
    adv_pub1: Optional[str] = None
    adv_pub2: Optional[str] = None
    adv_pub3: Optional[str] = None
    adv_pub4: Optional[str] = None
    adv_pub5: Optional[str] = None
    platform_id: Optional[int] = None
    partner_id: Optional[int] = None
    source_id: Optional[int] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'id': self.id,
            'tenant_id': self.tenant_id,
            'conversion_id': self.conversion_id,
            'offer_id': self.offer_id,
            'offer_name': self.offer_name,
            'datetime_conversion': self.datetime_conversion.isoformat() if self.datetime_conversion else None,
            'order_id': self.order_id,
            'usd_sale_amount': float(self.usd_sale_amount) if self.usd_sale_amount else 0.0,
            'usd_payout': float(self.usd_payout) if self.usd_payout else 0.0,
            'aff_sub': self.aff_sub,
            'aff_sub2': self.aff_sub2,
            'aff_sub3': self.aff_sub3,
            'aff_sub4': self.aff_sub4,
            'adv_pub1': self.adv_pub1,
            'adv_pub2': self.adv_pub2,
            'adv_pub3': self.adv_pub3,
            'adv_pub4': self.adv_pub4,
            'adv_pub5': self.adv_pub5,
            'status': self.status,
            'received_at': self.received_at.isoformat() if self.received_at else None,
            'tenant_name': self.tenant_name,
            'platform_id': self.platform_id,
            'partner_id': self.partner_id,
            'source_id': self.source_id
        }

@dataclass
class PartnerSummary:
    """Partneræ±‡æ€»æ•°æ®ç±»"""
    partner_name: str
    partner_id: Optional[int]
    total_records: int
    total_amount: Decimal
    amount_formatted: str
    sources: List[str]
    sources_count: int
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'partner_name': self.partner_name,
            'partner_id': self.partner_id,
            'total_records': self.total_records,
            'total_amount': float(self.total_amount),
            'amount_formatted': self.amount_formatted,
            'sources': self.sources,
            'sources_count': self.sources_count
        }

class PostbackDatabase:
    """PostBackæ•°æ®åº“è®¿é—®ç±»"""
    
    def __init__(self, host: str = "34.124.206.16", port: int = 5432, 
                 database: str = "postback_db", user: str = "postback_admin",
                 password: str = "ByteC2024PostBack_CloudSQL"):
        self.host = host
        self.port = port
        self.database = database
        self.user = user
        self.password = password
        self.connection_string = f"postgresql://{user}:{password}@{host}:{port}/{database}"
        self.pool = None
        
        # åˆå§‹åŒ–æ˜ å°„ç®¡ç†å™¨
        self.mapping_manager = MappingManager({
            'host': host,
            'port': port,
            'database': database,
            'user': user,
            'password': password
        })
        
    async def init_pool(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± """
        try:
            self.pool = await asyncpg.create_pool(
                self.connection_string,
                min_size=2,
                max_size=10,
                command_timeout=30
            )
            
            # åˆå§‹åŒ–æ˜ å°„ç³»çµ±
            await self.mapping_manager.initialize_all_mappings()
            
            logger.info("âœ… æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def close_pool(self):
        """å…³é—­æ•°æ®åº“è¿æ¥æ± """
        if self.pool:
            await self.pool.close()
            
        # é—œé–‰æ˜ å°„ç®¡ç†å™¨
        if self.mapping_manager:
            await self.mapping_manager.close_pool()
            
        logger.info("âœ… æ•°æ®åº“è¿æ¥æ± å·²å…³é—­")
    
    async def get_available_partners(self) -> List[str]:
        """è·å–å¯ç”¨çš„Partneråˆ—è¡¨ - ç›´æ¥å¾ conversions è¡¨æŸ¥è©¢"""
        if not self.pool:
            await self.init_pool()
        
        try:
            async with self.pool.acquire() as conn:
                # ç›´æ¥å¾ conversions è¡¨ç²å–å¯ç”¨çš„Partneråˆ—è¡¨
                query = """
                SELECT DISTINCT c.partner
                FROM conversions c
                WHERE c.partner IS NOT NULL
                ORDER BY c.partner
                """
                rows = await conn.fetch(query)
                partners = [row['partner'] for row in rows]
                
                # å¦‚æœæœ‰æ•¸æ“šï¼Œé»˜èªæ·»åŠ  "ALL" é¸é …
                if partners:
                    partners.insert(0, "ALL")
                
                logger.info(f"âœ… ç²å–å¯ç”¨Partneråˆ—è¡¨: {partners}")
                return partners
        except Exception as e:
            logger.error(f"âŒ è·å–Partneråˆ—è¡¨å¤±è´¥: {e}")
            import traceback
            logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            raise
    
    async def get_conversions_by_partner(self, partner_name: str = None, 
                                       start_date: datetime = None,
                                       end_date: datetime = None,
                                       limit: Optional[int] = None) -> List[ConversionRecord]:
        """
        æ ¹æ®Partnerè·å–è½¬åŒ–è®°å½• - ä½¿ç”¨åˆ†æ‰¹æŸ¥è©¢å„ªåŒ–å¤§æ•¸æ“šé‡è™•ç†
        
        Args:
            partner_name: Partneråç§°ï¼ŒNoneè¡¨ç¤ºè·å–æ‰€æœ‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            limit: é™åˆ¶è¿”å›çš„è®°å½•æ•°é‡
            
        Returns:
            List[ConversionRecord]: è½¬åŒ–è®°å½•åˆ—è¡¨
        """
        if not self.pool:
            await self.init_pool()
        
        # åˆ†æ‰¹è™•ç†é…ç½®
        BATCH_SIZE = 5000
        MAX_RETRIES = 3
        BATCH_TIMEOUT = 30
        
        try:
            async with self.pool.acquire() as conn:
                # é¦–å…ˆç²å–ç¸½è¨˜éŒ„æ•¸ç”¨æ–¼é€²åº¦é¡¯ç¤º
                count_query = """
                SELECT COUNT(*) as total_count
                FROM conversions c
                WHERE 1=1
                """
                
                count_params = []
                count_param_count = 0
                
                # æ·»åŠ Partneréæ¿¾
                if partner_name and partner_name.upper() != 'ALL':
                    count_param_count += 1
                    count_query += f" AND c.partner = ${count_param_count}"
                    count_params.append(partner_name)
                
                # æ·»åŠ æ™‚é–“ç¯„åœéæ¿¾
                if start_date:
                    count_param_count += 1
                    count_query += f" AND DATE(c.datetime_conversion) >= ${count_param_count}::date"
                    if hasattr(start_date, 'replace'):
                        start_date = start_date.replace(microsecond=0, tzinfo=None)
                    count_params.append(start_date)
                
                if end_date:
                    count_param_count += 1
                    count_query += f" AND DATE(c.datetime_conversion) <= ${count_param_count}::date"
                    if hasattr(end_date, 'replace'):
                        end_date = end_date.replace(microsecond=0, tzinfo=None)
                    count_params.append(end_date)
                
                # ç²å–ç¸½è¨˜éŒ„æ•¸
                total_count_row = await conn.fetchrow(count_query, *count_params)
                total_count = total_count_row['total_count'] if total_count_row else 0
                
                # å¦‚æœæœ‰limité™åˆ¶ï¼Œèª¿æ•´ç¸½æ•¸
                if limit and limit < total_count:
                    total_count = limit
                
                logger.info(f"ğŸ” åŸ·è¡ŒæŸ¥è©¢: Partner={partner_name}, æ—¥æœŸ={start_date} è‡³ {end_date}, ç¸½è¨˜éŒ„æ•¸={total_count:,}")
                
                # å¦‚æœè¨˜éŒ„æ•¸è¼ƒå°‘ï¼Œä½¿ç”¨åŸæœ‰é‚è¼¯
                if total_count <= BATCH_SIZE:
                    return await self._fetch_single_batch(conn, partner_name, start_date, end_date, limit)
                
                # å¤§æ•¸æ“šé‡ä½¿ç”¨åˆ†æ‰¹è™•ç†
                logger.info(f"ğŸ“Š æ•¸æ“šé‡è¼ƒå¤§ ({total_count:,} æ¢)ï¼Œå•Ÿç”¨åˆ†æ‰¹è™•ç† (æ¯æ‰¹ {BATCH_SIZE:,} æ¢)")
                
                # æ§‹å»ºåŸºç¤æŸ¥è©¢
                base_query = """
                SELECT 
                    c.id,
                    COALESCE(c.tenant_id, 1) as tenant_id,
                    COALESCE(c.conversion_id::text, c.id::text) as conversion_id,
                    c.offer_id,
                    c.offer_name,
                    c.datetime_conversion,
                    COALESCE(c.order_id, c.conversion_id::text) as order_id,
                    COALESCE(c.sale_amount, c.usd_sale_amount, 0) as usd_sale_amount,
                    COALESCE(c.payout, c.usd_payout, 0) as usd_payout,
                    c.aff_sub,
                    COALESCE(c.aff_sub2, '') as aff_sub2,
                    COALESCE(c.aff_sub3, '') as aff_sub3,
                    COALESCE(c.aff_sub4, '') as aff_sub4,
                    COALESCE(c.adv_sub1, '') as adv_pub1,
                    COALESCE(c.adv_sub2, '') as adv_pub2,
                    COALESCE(c.adv_sub3, '') as adv_pub3,
                    COALESCE(c.adv_sub4, '') as adv_pub4,
                    COALESCE(c.adv_sub5, '') as adv_pub5,
                    COALESCE(c.conversion_status, 'pending') as status,
                    COALESCE(c.created_at, c.datetime_conversion, NOW()) as received_at,
                    COALESCE(c.partner, 'Unknown') as partner_name,
                    c.platform_id,
                    c.partner_id
                FROM conversions c
                WHERE 1=1
                """
                
                params = []
                param_count = 0
                
                # æ·»åŠ Partneréæ¿¾
                if partner_name and partner_name.upper() != 'ALL':
                    param_count += 1
                    base_query += f" AND c.partner = ${param_count}"
                    params.append(partner_name)
                
                # æ·»åŠ æ™‚é–“ç¯„åœéæ¿¾
                if start_date:
                    param_count += 1
                    base_query += f" AND DATE(c.datetime_conversion) >= ${param_count}::date"
                    params.append(start_date)
                
                if end_date:
                    param_count += 1
                    base_query += f" AND DATE(c.datetime_conversion) <= ${param_count}::date"
                    params.append(end_date)
                
                # æ·»åŠ æ’åº
                base_query += " ORDER BY c.datetime_conversion DESC"
                
                # åˆ†æ‰¹è™•ç†
                all_conversions = []
                offset = 0
                total_processed = 0
                batch_number = 1
                
                while total_processed < total_count:
                    # è¨ˆç®—ç•¶å‰æ‰¹æ¬¡å¤§å°
                    current_batch_size = min(BATCH_SIZE, total_count - total_processed)
                    if limit and total_processed + current_batch_size > limit:
                        current_batch_size = limit - total_processed
                    
                    # æ§‹å»ºæ‰¹æ¬¡æŸ¥è©¢
                    batch_query = base_query + f" LIMIT {current_batch_size} OFFSET {offset}"
                    
                    # åŸ·è¡Œæ‰¹æ¬¡æŸ¥è©¢ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰
                    batch_rows = await self._fetch_batch_with_retry(
                        conn, batch_query, params, batch_number, 
                        MAX_RETRIES, BATCH_TIMEOUT, partner_name
                    )
                    
                    if not batch_rows:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_number} è¿”å›ç©ºçµæœï¼Œåœæ­¢è™•ç†")
                        break
                    
                    # è™•ç†ç•¶å‰æ‰¹æ¬¡
                    batch_conversions = []
                    for row in batch_rows:
                        # ç²å– partner_id å’Œ source_id
                        partner_id = row.get('partner_id')
                        if not partner_id and row.get('partner_name'):
                            partner_id = await self.mapping_manager.get_partner_id(row['partner_name'])
                        
                        source_id = None
                        if row.get('aff_sub'):
                            source_id = await self.mapping_manager.get_or_create_source_id(row['aff_sub'])
                        
                        batch_conversions.append(ConversionRecord(
                            id=row['id'],
                            tenant_id=row['tenant_id'],
                            conversion_id=row['conversion_id'],
                            offer_id=row['offer_id'],
                            offer_name=row['offer_name'],
                            datetime_conversion=row['datetime_conversion'],
                            order_id=row['order_id'],
                            usd_sale_amount=Decimal(str(row['usd_sale_amount'])) if row['usd_sale_amount'] else Decimal('0'),
                            usd_payout=Decimal(str(row['usd_payout'])) if row['usd_payout'] else Decimal('0'),
                            aff_sub=row['aff_sub'],
                            aff_sub2=row['aff_sub2'],
                            aff_sub3=row['aff_sub3'],
                            aff_sub4=row['aff_sub4'],
                            adv_pub1=row['adv_pub1'],
                            adv_pub2=row['adv_pub2'],
                            adv_pub3=row['adv_pub3'],
                            adv_pub4=row['adv_pub4'],
                            adv_pub5=row['adv_pub5'],
                            status=row['status'],
                            received_at=row['received_at'],
                            tenant_name=f"tenant_{row['tenant_id']}",
                            platform_id=row['platform_id'],
                            partner_id=partner_id,
                            source_id=source_id
                        ))
                    
                    all_conversions.extend(batch_conversions)
                    total_processed += len(batch_rows)
                    
                    # é¡¯ç¤ºé€²åº¦
                    percentage = (total_processed / total_count) * 100
                    logger.info(f"ğŸ“ˆ æ‰¹æ¬¡ {batch_number} å®Œæˆ: {total_processed:,}/{total_count:,} ({percentage:.1f}%)")
                    
                    offset += current_batch_size
                    batch_number += 1
                    
                    # å¦‚æœæ‰¹æ¬¡å°æ–¼é æœŸå¤§å°æˆ–é”åˆ°limitï¼Œèªªæ˜å·²ç¶“å®Œæˆ
                    if len(batch_rows) < current_batch_size or (limit and total_processed >= limit):
                        break
                
                logger.info(f"âœ… åˆ†æ‰¹æŸ¥è©¢å®Œæˆ: ç¸½å…±è™•ç† {total_processed:,} æ¢è¨˜éŒ„ï¼Œ{batch_number-1} å€‹æ‰¹æ¬¡")
                return all_conversions
                
        except Exception as e:
            logger.error(f"âŒ è·å–è½¬åŒ–è®°å½•å¤±è´¥: {e}")
            import traceback
            logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            raise

    async def _fetch_single_batch(self, conn, partner_name: str = None, 
                                start_date: datetime = None,
                                end_date: datetime = None,
                                limit: Optional[int] = None) -> List[ConversionRecord]:
        """è™•ç†å°æ•¸æ“šé‡çš„å–®æ‰¹æ¬¡æŸ¥è©¢"""
        base_query = """
        SELECT 
            c.id,
            COALESCE(c.tenant_id, 1) as tenant_id,
            COALESCE(c.conversion_id::text, c.id::text) as conversion_id,
            c.offer_id,
            c.offer_name,
            c.datetime_conversion,
            COALESCE(c.order_id, c.conversion_id::text) as order_id,
            COALESCE(c.sale_amount, c.usd_sale_amount, 0) as usd_sale_amount,
            COALESCE(c.payout, c.usd_payout, 0) as usd_payout,
            c.aff_sub,
            COALESCE(c.aff_sub2, '') as aff_sub2,
            COALESCE(c.aff_sub3, '') as aff_sub3,
            COALESCE(c.aff_sub4, '') as aff_sub4,
            COALESCE(c.adv_sub1, '') as adv_pub1,
            COALESCE(c.adv_sub2, '') as adv_pub2,
            COALESCE(c.adv_sub3, '') as adv_pub3,
            COALESCE(c.adv_sub4, '') as adv_pub4,
            COALESCE(c.adv_sub5, '') as adv_pub5,
            COALESCE(c.conversion_status, 'pending') as status,
            COALESCE(c.created_at, c.datetime_conversion, NOW()) as received_at,
            COALESCE(c.partner, 'Unknown') as partner_name,
            c.platform_id,
            c.partner_id
        FROM conversions c
        WHERE 1=1
        """
        
        params = []
        param_count = 0
        
        # æ·»åŠ Partneréæ¿¾
        if partner_name and partner_name.upper() != 'ALL':
            param_count += 1
            base_query += f" AND c.partner = ${param_count}"
            params.append(partner_name)
        
        # æ·»åŠ æ™‚é–“ç¯„åœéæ¿¾
        if start_date:
            param_count += 1
            base_query += f" AND DATE(c.datetime_conversion) >= ${param_count}::date"
            params.append(start_date)
        
        if end_date:
            param_count += 1
            base_query += f" AND DATE(c.datetime_conversion) <= ${param_count}::date"
            params.append(end_date)
        
        # æ·»åŠ æ’åº
        base_query += " ORDER BY c.datetime_conversion DESC"
        
        # æ·»åŠ limité™åˆ¶
        if limit:
            param_count += 1
            base_query += f" LIMIT ${param_count}"
            params.append(limit)
        
        rows = await conn.fetch(base_query, *params)
        
        conversions = []
        for row in rows:
            # ç²å– partner_id å’Œ source_id
            partner_id = row.get('partner_id')
            if not partner_id and row.get('partner_name'):
                partner_id = await self.mapping_manager.get_partner_id(row['partner_name'])
            
            source_id = None
            if row.get('aff_sub'):
                source_id = await self.mapping_manager.get_or_create_source_id(row['aff_sub'])
            
            conversions.append(ConversionRecord(
                id=row['id'],
                tenant_id=row['tenant_id'],
                conversion_id=row['conversion_id'],
                offer_id=row['offer_id'],
                offer_name=row['offer_name'],
                datetime_conversion=row['datetime_conversion'],
                order_id=row['order_id'],
                usd_sale_amount=Decimal(str(row['usd_sale_amount'])) if row['usd_sale_amount'] else Decimal('0'),
                usd_payout=Decimal(str(row['usd_payout'])) if row['usd_payout'] else Decimal('0'),
                aff_sub=row['aff_sub'],
                aff_sub2=row['aff_sub2'],
                aff_sub3=row['aff_sub3'],
                aff_sub4=row['aff_sub4'],
                adv_pub1=row['adv_pub1'],
                adv_pub2=row['adv_pub2'],
                adv_pub3=row['adv_pub3'],
                adv_pub4=row['adv_pub4'],
                adv_pub5=row['adv_pub5'],
                status=row['status'],
                received_at=row['received_at'],
                tenant_name=f"tenant_{row['tenant_id']}",
                platform_id=row['platform_id'],
                partner_id=partner_id,
                source_id=source_id
            ))
        
        return conversions

    async def _fetch_batch_with_retry(self, conn, query: str, params: list, 
                                    batch_number: int, max_retries: int, 
                                    timeout: int, partner_name: str):
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„æ‰¹æ¬¡æŸ¥è©¢"""
        import asyncio
        
        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"ğŸ”„ åŸ·è¡Œæ‰¹æ¬¡ {batch_number} (ç¬¬ {attempt} æ¬¡å˜—è©¦)")
                
                # å¸¶è¶…æ™‚çš„æŸ¥è©¢
                rows = await asyncio.wait_for(
                    conn.fetch(query, *params),
                    timeout=timeout
                )
                
                logger.info(f"âœ… æ‰¹æ¬¡ {batch_number} æŸ¥è©¢æˆåŠŸ: {len(rows)} æ¢è¨˜éŒ„")
                return rows
                
            except asyncio.TimeoutError:
                logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_number} æŸ¥è©¢è¶…æ™‚ ({timeout}ç§’) - ç¬¬ {attempt} æ¬¡å˜—è©¦")
                if attempt == max_retries:
                    logger.error(f"âŒ æ‰¹æ¬¡ {batch_number} åœ¨ {max_retries} æ¬¡é‡è©¦å¾Œä»ç„¶è¶…æ™‚ï¼Œè·³éæ­¤æ‰¹æ¬¡")
                    return []
                else:
                    logger.info(f"ğŸ”„ å°‡åœ¨ 2 ç§’å¾Œé‡è©¦æ‰¹æ¬¡ {batch_number}")
                    await asyncio.sleep(2)
                    
            except Exception as e:
                logger.error(f"âŒ æ‰¹æ¬¡ {batch_number} æŸ¥è©¢å¤±è´¥ (ç¬¬ {attempt} æ¬¡å˜—è©¦): {e}")
                if attempt == max_retries:
                    logger.error(f"âŒ æ‰¹æ¬¡ {batch_number} åœ¨ {max_retries} æ¬¡é‡è©¦å¾Œä»ç„¶å¤±æ•—ï¼Œè·³éæ­¤æ‰¹æ¬¡")
                    return []
                else:
                    logger.info(f"ğŸ”„ å°‡åœ¨ 2 ç§’å¾Œé‡è©¦æ‰¹æ¬¡ {batch_number}")
                    await asyncio.sleep(2)
        
        return []
    
    async def get_partner_summary(self, partner_name: str = None,
                                start_date: datetime = None,
                                end_date: datetime = None,
                                limit: Optional[int] = None) -> List[PartnerSummary]:
        """
        è·å–Partneræ±‡æ€»æ•°æ® - ä½¿ç”¨ç°¡åŒ–çš„ç›´æ¥æ¬„ä½æŸ¥è©¢
        
        Args:
            partner_name: Partneråç§°ï¼Œä¸ºNoneæˆ–"ALL"æ—¶è·å–æ‰€æœ‰Partner
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            limit: é™åˆ¶å¤„ç†çš„è®°å½•æ•°é‡
            
        Returns:
            List[PartnerSummary]: Partneræ±‡æ€»åˆ—è¡¨
        """
        if not self.pool:
            await self.init_pool()
        
        # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´ï¼ˆè¿‡å»7å¤©ï¼‰
        if not end_date:
            end_date = datetime.now()
        if not start_date:
            start_date = end_date - timedelta(days=7)
        
        try:
            async with self.pool.acquire() as conn:
                # ä½¿ç”¨ç°¡åŒ–çš„ç›´æ¥æ¬„ä½æŸ¥è©¢
                base_query = """
                SELECT 
                    c.partner,
                    COUNT(*) as total_records,
                    SUM(COALESCE(c.sale_amount, c.usd_sale_amount, 0)) as total_amount,
                    array_agg(DISTINCT c.aff_sub) FILTER (WHERE c.aff_sub IS NOT NULL) as sources
                FROM conversions c
                WHERE 1=1
                """
                
                params = []
                param_count = 0
                
                # æ·»åŠ Partneréæ¿¾
                if partner_name and partner_name.upper() != 'ALL':
                    param_count += 1
                    base_query += f" AND c.partner = ${param_count}"
                    params.append(partner_name)
                
                # æ·»åŠ æ™‚é–“ç¯„åœéæ¿¾
                if start_date:
                    param_count += 1
                    base_query += f" AND DATE(c.datetime_conversion) >= ${param_count}::date"
                    if hasattr(start_date, 'replace'):
                        start_date = start_date.replace(microsecond=0, tzinfo=None)
                    params.append(start_date)
                
                if end_date:
                    param_count += 1
                    base_query += f" AND DATE(c.datetime_conversion) <= ${param_count}::date"
                    if hasattr(end_date, 'replace'):
                        end_date = end_date.replace(microsecond=0, tzinfo=None)
                    params.append(end_date)
                
                # æ·»åŠ åˆ†çµ„å’Œæ’åº
                base_query += " GROUP BY c.partner ORDER BY total_records DESC"
                
                # æ·»åŠ limité™åˆ¶
                if limit:
                    param_count += 1
                    base_query += f" LIMIT ${param_count}"
                    params.append(limit)
                
                logger.info(f"ğŸ” åŸ·è¡ŒPartneræ±‡æ€»æŸ¥è©¢: Partner={partner_name}, æ—¥æœŸ={start_date} è‡³ {end_date}")
                
                rows = await conn.fetch(base_query, *params)
                
                summaries = []
                for row in rows:
                    partner_name_db = row['partner'] or 'Unknown'
                    total_records = row['total_records']
                    total_amount = Decimal(str(row['total_amount'])) if row['total_amount'] else Decimal('0')
                    sources = row['sources'] or []
                    
                    # ç²å– partner_id
                    partner_id = await self.mapping_manager.get_partner_id(partner_name_db)
                    
                    summary = PartnerSummary(
                        partner_name=partner_name_db,
                        partner_id=partner_id,
                        total_records=total_records,
                        total_amount=total_amount,
                        amount_formatted=f"${total_amount:,.2f}",
                        sources=sources,
                        sources_count=len(sources)
                    )
                    summaries.append(summary)
                
                logger.info(f"âœ… è·å–Partneræ±‡æ€»æˆåŠŸ: {len(summaries)} ä¸ªPartner")
                return summaries
                
        except Exception as e:
            logger.error(f"âŒ è·å–Partneræ±‡æ€»å¤±è´¥: {e}")
            import traceback
            logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            raise
    
    async def get_conversion_dataframe(self, partner_name: str = None,
                                     start_date: datetime = None,
                                     end_date: datetime = None,
                                     limit: Optional[int] = None) -> pd.DataFrame:
        """
        è·å–è½¬åŒ–æ•°æ®çš„DataFrameæ ¼å¼ï¼ˆå¢å¼·ç‰ˆå¸¶æ˜ å°„ï¼‰
        
        Args:
            partner_name: Partneråç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            limit: é™åˆ¶è¿”å›çš„è®°å½•æ•°é‡
            
        Returns:
            pd.DataFrame: è½¬åŒ–æ•°æ®æ¡†
        """
        try:
            conversions = await self.get_conversions_by_partner(
                partner_name=partner_name,
                start_date=start_date,
                end_date=end_date,
                limit=limit
            )
            
            if not conversions:
                logger.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°è½¬åŒ–æ•°æ®: Partner={partner_name}")
                return pd.DataFrame()
            
            # è½¬æ¢ä¸ºDataFrame
            data = []
            for conv in conversions:
                # ç¢ºå®šPartneråç¨±
                partner_display = conv.partner_name if hasattr(conv, 'partner_name') and conv.partner_name else 'Unknown'
                if not partner_display or partner_display == 'Unknown':
                    # å˜—è©¦é€šéSourceæ¨æ–·Partner
                    if conv.aff_sub:
                        from config import match_source_to_partner
                        partner_display = match_source_to_partner(conv.aff_sub)
                
                # ç§»é™¤æ™‚å€ä¿¡æ¯ä»¥æ”¯æŒExcelè¼¸å‡º
                conversion_date = conv.datetime_conversion
                if conversion_date and hasattr(conversion_date, 'replace') and conversion_date.tzinfo:
                    conversion_date = conversion_date.replace(tzinfo=None)
                
                received_at = conv.received_at
                if received_at and hasattr(received_at, 'replace') and received_at.tzinfo:
                    received_at = received_at.replace(tzinfo=None)
                
                # å¤„ç†Sale Amount - æ ¹æ®config.pyä¸­çš„è®¾ç½®
                original_sale_amount = float(conv.usd_sale_amount) if conv.usd_sale_amount else 0.0
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºByteC partner
                import sys
                import os
                config_path = os.path.join(os.path.dirname(__file__), '../../../../')
                if config_path not in sys.path:
                    sys.path.append(config_path)
                
                import config
                is_bytec_partner = (
                    partner_display.upper() == 'BYTEC' or
                    partner_display.upper() == 'BYTEC-NETWORK' or
                    'BYTEC' in partner_display.upper()
                )
                
                # åº”ç”¨mockupè°ƒæ•´ï¼ˆæ ¹æ®config.pyè®¾ç½®ï¼‰
                if is_bytec_partner:
                    processed_sale_amount = original_sale_amount * config.BYTEC_MOCKUP_MULTIPLIER  # ByteCä½¿ç”¨BYTEC_MOCKUP_MULTIPLIER
                else:
                    processed_sale_amount = original_sale_amount * config.MOCKUP_MULTIPLIER  # å…¶ä»–partnerä½¿ç”¨MOCKUP_MULTIPLIER
                
                # åŒ…å«æ‰€æœ‰æ•¸æ“šåº«æ¬„ä½ï¼ŒæŒ‰ç…§æ•¸æ“šåº«æ ¼å¼è¼¸å‡ºï¼Œéš±è—æŒ‡å®šæ¬„ä½ï¼ˆID, Tenant ID, Tenant, Received At, Status, Payout (USD), Platform IDï¼‰
                data.append({
                    'Conversion ID': conv.conversion_id,
                    'Offer ID': conv.offer_id,
                    'Offer Name': conv.offer_name,
                    'Datetime Conversion': conversion_date,
                    'Order ID': conv.order_id,
                    'USD Sale Amount': processed_sale_amount,  # ä½¿ç”¨è™•ç†å¾Œçš„é‡‘é¡
                    'Aff Sub': conv.aff_sub,
                    'Aff Sub2': conv.aff_sub2 if conv.aff_sub2 else '',
                    'Aff Sub3': conv.aff_sub3 if conv.aff_sub3 else '',
                    'Aff Sub4': conv.aff_sub4 if conv.aff_sub4 else '',
                    'Adv Pub1': conv.adv_pub1 if conv.adv_pub1 else '',
                    'Adv Pub2': conv.adv_pub2 if conv.adv_pub2 else '',
                    'Adv Pub3': conv.adv_pub3 if conv.adv_pub3 else '',
                    'Adv Pub4': conv.adv_pub4 if conv.adv_pub4 else '',
                    'Adv Pub5': conv.adv_pub5 if conv.adv_pub5 else '',
                    'Status': conv.status if conv.status else 'pending',
                    'Partner': partner_display,
                    'Partner ID': conv.partner_id,
                    'Source': conv.aff_sub if conv.aff_sub else 'Unknown',
                    'Source ID': conv.source_id
                })
            
            df = pd.DataFrame(data)
            
            # æ·»åŠ Partnerè¿‡æ»¤
            if partner_name and partner_name.upper() != 'ALL':
                df = df[df['Partner'].str.contains(partner_name, case=False, na=False)]
            
            # åº”ç”¨limité™åˆ¶
            if limit and len(df) > limit:
                logger.info(f"ğŸ“Š åº”ç”¨limité™åˆ¶: ä» {len(df)} æ¡è®°å½•é™åˆ¶åˆ° {limit} æ¡")
                df = df.head(limit)
            
            logger.info(f"âœ… è·å–è½¬åŒ–æ•°æ®æˆåŠŸ: {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            logger.error(f"âŒ è·å–è½¬åŒ–æ•°æ®DataFrameå¤±è´¥: {e}")
            raise
    
    async def insert_conversion_with_mapping(self, conversion_data: Dict[str, Any]) -> Optional[int]:
        """
        æ’å…¥è½‰åŒ–æ•¸æ“šä¸¦ä½¿ç”¨æ˜ å°„ç³»çµ±
        
        Args:
            conversion_data: è½‰åŒ–æ•¸æ“šå­—å…¸
            
        Returns:
            Optional[int]: æ’å…¥çš„è¨˜éŒ„IDï¼Œå¤±æ•—æ™‚è¿”å›None
        """
        if not self.pool:
            await self.init_pool()
        
        try:
            # æå–æ˜ å°„ä¿¡æ¯
            api_secret = conversion_data.get('api_secret')
            aff_sub = conversion_data.get('aff_sub')
            
            # ç²å–æ˜ å°„ID
            platform_id = None
            if api_secret:
                platform_id = await self.mapping_manager.get_platform_by_api_secret(api_secret)
            
            source_id = None
            partner_id = None
            if aff_sub:
                source_id = await self.mapping_manager.get_or_create_source_id(aff_sub)
                if source_id:
                    # é€šésource_idç²å–partner_id
                    async with self.pool.acquire() as conn:
                        partner_id = await conn.fetchval("""
                        SELECT partner_id FROM sources WHERE id = $1
                        """, source_id)
            
            async with self.pool.acquire() as conn:
                # æº–å‚™raw_data JSON
                raw_data = {
                    'offer_id': conversion_data.get('offer_id'),
                    'order_id': conversion_data.get('order_id'),
                    'aff_sub2': conversion_data.get('aff_sub2', ''),
                    'aff_sub3': conversion_data.get('aff_sub3', ''),
                    'aff_sub4': conversion_data.get('aff_sub4', ''),
                    'status': conversion_data.get('status', 'approved'),
                    'api_secret': api_secret,
                    'platform_id': platform_id,
                    'source_id': source_id,
                    'datetime_conversion': conversion_data.get('datetime_conversion'),
                    'original_data': conversion_data
                }
                
                # æ’å…¥åˆ°conversionsè¡¨ï¼ˆåƒ…ä½¿ç”¨å¯¦éš›å­˜åœ¨çš„æ¬„ä½ï¼‰
                conversion_id = await conn.fetchval("""
                INSERT INTO conversions (
                    tenant_id, conversion_id, offer_name,
                    usd_sale_amount, usd_payout, aff_sub,
                    event_time, raw_data, partner_id, created_at
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10
                )
                RETURNING id
                """,
                conversion_data.get('tenant_id', 1),
                conversion_data.get('conversion_id'),
                conversion_data.get('offer_name'),
                conversion_data.get('usd_sale_amount'),
                conversion_data.get('usd_payout'),
                conversion_data.get('aff_sub'),
                conversion_data.get('datetime_conversion'),
                json.dumps(raw_data),
                partner_id,
                conversion_data.get('created_at', datetime.now())
                )
                
                logger.info(f"âœ… æ’å…¥è½‰åŒ–æ•¸æ“šæˆåŠŸ: ID={conversion_id}, Platform={platform_id}, Partner={partner_id}, Source={source_id}")
                return conversion_id
                
        except Exception as e:
            logger.error(f"âŒ æ’å…¥è½‰åŒ–æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥ - ç°¡åŒ–ç‰ˆæœ¬ï¼Œåªæª¢æŸ¥å¯¦éš›å­˜åœ¨çš„è¡¨"""
        try:
            if not self.pool:
                await self.init_pool()
            
            async with self.pool.acquire() as conn:
                # æ£€æŸ¥æ•°æ®åº“è¿æ¥
                version = await conn.fetchval("SELECT version()")
                
                # æ£€æŸ¥ä¸»è¦æ•°æ®è¡¨
                conversions_count = await conn.fetchval("SELECT COUNT(*) FROM conversions")
                
                # æª¢æŸ¥å¯é¸è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨å‰‡è·³éï¼‰
                partners_count = 0
                platforms_count = 0
                sources_count = 0
                
                try:
                    partners_count = await conn.fetchval("SELECT COUNT(*) FROM business_partners")
                except:
                    logger.warning("business_partners è¡¨ä¸å­˜åœ¨ï¼Œè·³éæª¢æŸ¥")
                
                try:
                    platforms_count = await conn.fetchval("SELECT COUNT(*) FROM platforms")
                except:
                    logger.warning("platforms è¡¨ä¸å­˜åœ¨ï¼Œè·³éæª¢æŸ¥")
                
                try:
                    sources_count = await conn.fetchval("SELECT COUNT(*) FROM sources")
                except:
                    logger.warning("sources è¡¨ä¸å­˜åœ¨ï¼Œè·³éæª¢æŸ¥")
                
                # æª¢æŸ¥æ˜ å°„ç³»çµ±ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                mapping_summary = {}
                try:
                    mapping_summary = await self.mapping_manager.get_mapping_summary()
                except:
                    logger.warning("æ˜ å°„ç³»çµ±ä¸å¯ç”¨ï¼Œè·³éæª¢æŸ¥")
                
                # æª¢æŸ¥å¯ç”¨çš„partners
                available_partners = []
                try:
                    available_partners = await self.get_available_partners()
                except:
                    logger.warning("ç„¡æ³•ç²å–å¯ç”¨partnersåˆ—è¡¨")
                
                return {
                    'status': 'healthy',
                    'database_version': version,
                    'conversions_count': conversions_count,
                    'partners_count': partners_count,
                    'platforms_count': platforms_count,
                    'sources_count': sources_count,
                    'available_partners': available_partners,
                    'mapping_system': mapping_summary,
                    'connection_pool_size': self.pool.get_size() if self.pool else 0,
                    'timestamp': datetime.now().isoformat()
                }
        except Exception as e:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            return {
                'status': 'unhealthy',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            } 
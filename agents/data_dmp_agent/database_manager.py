#!/usr/bin/env python3
"""
DMP-Agent æ•¸æ“šåº«ç®¡ç†å™¨ - å¢å¼·ç‰ˆæœ¬
æ”¯æŒå®Œæ•´çš„è½‰åŒ–æ•¸æ“šå­˜å„²ï¼ŒåŒ…æ‹¬platformã€partnerã€sourceç­‰æ‰€æœ‰å­—æ®µ
å¾Reporter-Agenté·ç§»çš„Google Cloud SQLå­˜å„²é‚è¼¯
"""

import asyncio
import asyncpg
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
from decimal import Decimal

logger = logging.getLogger(__name__)

class EnhancedDMPDatabaseManager:
    """
    å¢å¼·ç‰ˆDMP-Agentæ•¸æ“šåº«ç®¡ç†å™¨
    æ”¯æŒå®Œæ•´çš„è½‰åŒ–æ•¸æ“šå­˜å„²ï¼ŒåŒ…æ‹¬ï¼š
    - platform å­—æ®µ
    - partner å­—æ®µï¼ˆæŒ‰ç…§config.pyæ˜ å°„ï¼‰
    - source å­—æ®µï¼ˆå¾aff_subç²å–ï¼‰
    - æ‰€æœ‰APIåƒæ•¸çš„å®Œæ•´å­˜å„²
    """
    
    def __init__(self, host: str = "34.124.206.16", port: int = 5432, 
                 database: str = "postback_db", user: str = "postback_admin",
                 password: str = "ByteC2024PostBack_CloudSQL"):
        self.host = host
        self.port = port
        self.database = database
        self.user = user
        self.password = password
        self.connection_string = f"postgresql://{user}:{password}@{host}:{port}/{database}"
        self.pool = None
        
    async def init_pool(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± """
        try:
            self.pool = await asyncpg.create_pool(
                self.connection_string,
                min_size=2,
                max_size=10,
                command_timeout=30
            )
            logger.info("âœ… å¢å¼·ç‰ˆDMP-Agentæ•¸æ“šåº«é€£æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ DMP-Agentæ•¸æ“šåº«é€£æ¥æ± åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def close_pool(self):
        """å…³é—­æ•°æ®åº“è¿æ¥æ± """
        if self.pool:
            await self.pool.close()
        logger.info("âœ… DMP-Agentæ•¸æ“šåº«é€£æ¥æ± å·²é—œé–‰")
    
    async def ensure_database_schema(self):
        """
        ç¢ºä¿æ•¸æ“šåº«schemaåŒ…å«æ‰€æœ‰æ–°å¢å­—æ®µ
        ç‚ºå‡ç´šç¾æœ‰æ•¸æ“šåº«æ·»åŠ ç¼ºå¤±å­—æ®µ
        """
        if not self.pool:
            await self.init_pool()
        
        logger.info("ğŸ”§ æª¢æŸ¥ä¸¦æ›´æ–°æ•¸æ“šåº«schema...")
        
        try:
            async with self.pool.acquire() as conn:
                # æª¢æŸ¥conversionsè¡¨æ˜¯å¦å­˜åœ¨æ–°å­—æ®µ
                schema_updates = [
                    # æ ¸å¿ƒåˆ†é¡å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS platform VARCHAR(100)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS partner VARCHAR(100)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS source VARCHAR(255)",
                    
                    # å®Œæ•´çš„é‡‘é¡å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS sale_amount DECIMAL(15,2)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS payout DECIMAL(15,2)", 
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS base_payout DECIMAL(15,2)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS bonus_payout DECIMAL(15,2)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS sale_amount_local DECIMAL(15,2)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS myr_sale_amount DECIMAL(15,2)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS payout_local DECIMAL(15,2)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS myr_payout DECIMAL(15,2)",
                    
                    # æ“´å±•çš„åƒæ•¸å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS aff_sub1 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS aff_sub2 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS aff_sub3 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS aff_sub4 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS aff_sub5 VARCHAR(255)",
                    
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS adv_sub VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS adv_sub1 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS adv_sub2 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS adv_sub3 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS adv_sub4 VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS adv_sub5 VARCHAR(255)",
                    
                    # ç‹€æ…‹å’Œæ¥­å‹™å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS conversion_status VARCHAR(50)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS offer_status VARCHAR(50)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS merchant_id VARCHAR(100)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS affiliate_remarks TEXT",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS click_id VARCHAR(255)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS click_time TIMESTAMP WITH TIME ZONE",
                    
                    # æ™‚é–“å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS datetime_conversion TIMESTAMP WITH TIME ZONE",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS datetime_conversion_updated TIMESTAMP WITH TIME ZONE",
                    
                    # è²¨å¹£å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS currency VARCHAR(3)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS conversion_currency VARCHAR(3)",
                    
                    # ä½£é‡‘å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS commission_rate DECIMAL(8,4)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS avg_commission_rate DECIMAL(8,4)",
                    
                    # è¨‚å–®ä¿¡æ¯
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS order_id VARCHAR(100)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS offer_id VARCHAR(50)",
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS offer_name TEXT",
                    
                    # ç³»çµ±æ™‚é–“æˆ³å­—æ®µ
                    "ALTER TABLE conversions ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP",
                ]
                
                # åŸ·è¡Œschemaæ›´æ–°
                for update_sql in schema_updates:
                    try:
                        await conn.execute(update_sql)
                    except Exception as e:
                        logger.warning(f"âš ï¸ Schemaæ›´æ–°å¤±æ•—: {update_sql[:50]}... - {str(e)}")
                
                # å‰µå»ºç´¢å¼•
                index_updates = [
                    "CREATE INDEX IF NOT EXISTS idx_conversions_platform ON conversions(platform)",
                    "CREATE INDEX IF NOT EXISTS idx_conversions_partner ON conversions(partner)",
                    "CREATE INDEX IF NOT EXISTS idx_conversions_source ON conversions(source)",
                    "CREATE INDEX IF NOT EXISTS idx_conversions_platform_partner ON conversions(platform, partner)",
                    "CREATE INDEX IF NOT EXISTS idx_conversions_datetime ON conversions(datetime_conversion)",
                    "CREATE INDEX IF NOT EXISTS idx_conversions_status ON conversions(conversion_status)",
                ]
                
                for index_sql in index_updates:
                    try:
                        await conn.execute(index_sql)
                    except Exception as e:
                        logger.warning(f"âš ï¸ ç´¢å¼•å‰µå»ºå¤±æ•—: {index_sql[:50]}... - {str(e)}")
                
                logger.info("âœ… æ•¸æ“šåº«schemaæ›´æ–°å®Œæˆ")
                
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šåº«schemaæ›´æ–°å¤±æ•—: {str(e)}")
            raise
    
    async def insert_conversion_enhanced(self, conversion_data: Dict[str, Any]) -> Optional[int]:
        """
        æ’å…¥å–®ä¸€è½‰åŒ–æ•¸æ“šåˆ°æ•¸æ“šåº« - å¢å¼·ç‰ˆæœ¬
        """
        def safe_str(value):
            """å®‰å…¨åœ°å°‡å€¼è½‰æ›ç‚ºå­—ç¬¦ä¸²"""
            if value is None:
                return None
            return str(value)
        
        def safe_float(value):
            """å®‰å…¨åœ°å°‡å€¼è½‰æ›ç‚ºæµ®é»æ•¸"""
            if value is None or value == '':
                return None
            try:
                return float(value)
            except (ValueError, TypeError):
            return None
    
        def safe_int(value):
            """å®‰å…¨åœ°å°‡å€¼è½‰æ›ç‚ºæ•´æ•¸"""
            if value is None or value == '':
                return None
            try:
                return int(value)
            except (ValueError, TypeError):
                return None
        
        def safe_datetime(value):
            """å®‰å…¨åœ°å°‡å€¼è½‰æ›ç‚ºdatetimeå°è±¡"""
            if value is None or value == '':
                logger.debug(f"ğŸ•’ safe_datetime: ç©ºå€¼è¼¸å…¥")
                return None
            if isinstance(value, datetime):
                logger.debug(f"ğŸ•’ safe_datetime: datetimeå°è±¡è¼¸å…¥ = {value}")
                return value
            try:
                # å˜—è©¦è§£æISOæ ¼å¼çš„æ™‚é–“å­—ç¬¦ä¸²
                if isinstance(value, str):
                    logger.debug(f"ğŸ•’ safe_datetime: å­—ç¬¦ä¸²è¼¸å…¥ = '{value}'")
                    # è™•ç†å¤šç¨®æ™‚é–“æ ¼å¼
                    for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%S.%f']:
                        try:
                            parsed_dt = datetime.strptime(value, fmt)
                            logger.debug(f"ğŸ•’ safe_datetime: æˆåŠŸè§£æ '{value}' â†’ {parsed_dt} (æ ¼å¼: {fmt})")
                            
                            # ğŸ”§ æ™‚å€ä¿®å¾©ï¼šAPI è¿”å›çš„æ™‚é–“æ‡‰è©²è¢«è§£é‡‹ç‚º UTC æ™‚é–“
                            if parsed_dt.tzinfo is None:
                                from datetime import timezone
                                parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                                logger.info(f"ğŸ•’ safe_datetime: å°‡APIæ™‚é–“è§£é‡‹ç‚ºUTC â†’ åŸå§‹: '{value}' çµæœ: {parsed_dt}")
                            
                            return parsed_dt
                        except ValueError:
                            continue
                    # å¦‚æœä¸Šè¿°æ ¼å¼éƒ½ä¸åŒ¹é…ï¼Œå˜—è©¦ä½¿ç”¨dateutil parser
                    from dateutil import parser
                    parsed_dt = parser.parse(value)
                    logger.debug(f"ğŸ•’ safe_datetime: dateutilè§£æ '{value}' â†’ {parsed_dt}")
                    
                    # ğŸ”§ æ™‚å€ä¿®å¾©ï¼šdateutil è§£æçµæœä¹Ÿéœ€è¦æª¢æŸ¥æ™‚å€
                    if parsed_dt.tzinfo is None:
                        from datetime import timezone
                        parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                        logger.info(f"ğŸ•’ safe_datetime: dateutilçµæœè¨­ç½®ç‚ºUTCæ™‚å€ â†’ åŸå§‹: '{value}' çµæœ: {parsed_dt}")
                    
                    return parsed_dt
                logger.warning(f"ğŸ•’ safe_datetime: ä¸æ”¯æŒçš„é¡å‹ {type(value)}: {value}")
                return None
            except (ValueError, TypeError, ImportError) as e:
                logger.error(f"ğŸ•’ safe_datetime: è§£æå¤±æ•— '{value}': {e}")
            return None
    
        if not self.pool:
            await self.init_pool()
        
        try:
            async with self.pool.acquire() as conn:
                # æº–å‚™å®Œæ•´çš„æ’å…¥SQL
                insert_sql = """
                INSERT INTO conversions (
                    -- æ ¸å¿ƒåˆ†é¡å­—æ®µ
                    platform, partner, source,
                    
                    -- æ ¸å¿ƒè½‰åŒ–å­—æ®µ
                    conversion_id, offer_id, offer_name, order_id,
                    
                    -- æ™‚é–“å­—æ®µ
                    datetime_conversion, datetime_conversion_updated, click_time,
                    
                    -- å®Œæ•´é‡‘é¡å­—æ®µ
                    sale_amount_local, myr_sale_amount, usd_sale_amount,
                    payout_local, myr_payout, usd_payout,
                    sale_amount, payout, base_payout, bonus_payout,
                    
                    -- è²¨å¹£å­—æ®µ
                    currency, conversion_currency,
                    
                    -- å»£å‘Šä¸»åƒæ•¸
                    adv_sub, adv_sub1, adv_sub2, adv_sub3, adv_sub4, adv_sub5,
                    
                    -- ç™¼å¸ƒå•†åƒæ•¸
                    aff_sub, aff_sub1, aff_sub2, aff_sub3, aff_sub4, aff_sub5,
                    
                    -- ç‹€æ…‹å­—æ®µ
                    conversion_status, offer_status,
                    
                    -- æ¥­å‹™å­—æ®µ
                    merchant_id, affiliate_remarks, click_id,
                    
                    -- ä½£é‡‘å­—æ®µ
                    commission_rate, avg_commission_rate,
                    
                    -- ç³»çµ±å­—æ®µ
                    tenant_id, raw_data, event_time, created_at
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10,
                    $11, $12, $13, $14, $15, $16, $17, $18, $19, $20,
                    $21, $22, $23, $24, $25, $26, $27, $28, $29, $30,
                    $31, $32, $33, $34, $35, $36, $37, $38, $39, $40,
                    $41, $42, $43, $44, $45
                )
                ON CONFLICT (conversion_id) DO UPDATE SET
                    platform = EXCLUDED.platform,
                    partner = EXCLUDED.partner,
                    source = EXCLUDED.source,
                    usd_sale_amount = EXCLUDED.usd_sale_amount,
                    usd_payout = EXCLUDED.usd_payout,
                    raw_data = EXCLUDED.raw_data,
                    updated_at = CURRENT_TIMESTAMP
                RETURNING id
                """
                
                # æº–å‚™åƒæ•¸
                params = [
                    # æ ¸å¿ƒåˆ†é¡å­—æ®µ
                    safe_str(conversion_data.get('platform')),
                    safe_str(conversion_data.get('partner')),
                    safe_str(conversion_data.get('source')),
                    
                    # æ ¸å¿ƒè½‰åŒ–å­—æ®µ
                    safe_str(conversion_data.get('conversion_id')),
                    safe_str(conversion_data.get('offer_id')),
                    safe_str(conversion_data.get('offer_name')),
                    safe_str(conversion_data.get('order_id')),
                    
                    # æ™‚é–“å­—æ®µ
                    safe_datetime(conversion_data.get('datetime_conversion')),
                    safe_datetime(conversion_data.get('datetime_conversion_updated')),
                    safe_datetime(conversion_data.get('click_time')),
                    
                    # å®Œæ•´é‡‘é¡å­—æ®µ
                    safe_float(conversion_data.get('sale_amount_local')),
                    safe_float(conversion_data.get('myr_sale_amount')),
                    safe_float(conversion_data.get('usd_sale_amount')),
                    safe_float(conversion_data.get('payout_local')),
                    safe_float(conversion_data.get('myr_payout')),
                    safe_float(conversion_data.get('usd_payout')),
                    safe_float(conversion_data.get('sale_amount')),
                    safe_float(conversion_data.get('payout')),
                    safe_float(conversion_data.get('base_payout')),
                    safe_float(conversion_data.get('bonus_payout')),
                    
                    # è²¨å¹£å­—æ®µ
                    safe_str(conversion_data.get('currency')),
                    safe_str(conversion_data.get('conversion_currency')),
                    
                    # å»£å‘Šä¸»åƒæ•¸
                    safe_str(conversion_data.get('adv_sub')),
                    safe_str(conversion_data.get('adv_sub1')),
                    safe_str(conversion_data.get('adv_sub2')),
                    safe_str(conversion_data.get('adv_sub3')),
                    safe_str(conversion_data.get('adv_sub4')),
                    safe_str(conversion_data.get('adv_sub5')),
                    
                    # ç™¼å¸ƒå•†åƒæ•¸
                    safe_str(conversion_data.get('aff_sub')),
                    safe_str(conversion_data.get('aff_sub1')),
                    safe_str(conversion_data.get('aff_sub2')),
                    safe_str(conversion_data.get('aff_sub3')),
                    safe_str(conversion_data.get('aff_sub4')),
                    safe_str(conversion_data.get('aff_sub5')),
                    
                    # ç‹€æ…‹å­—æ®µ
                    safe_str(conversion_data.get('conversion_status')),
                    safe_str(conversion_data.get('offer_status')),
                    
                    # æ¥­å‹™å­—æ®µ
                    safe_str(conversion_data.get('merchant_id')),
                    safe_str(conversion_data.get('affiliate_remarks')),
                    safe_str(conversion_data.get('click_id')),
                    
                    # ä½£é‡‘å­—æ®µ
                    safe_float(conversion_data.get('commission_rate')),
                    safe_float(conversion_data.get('avg_commission_rate')),
                    
                    # ç³»çµ±å­—æ®µ
                    safe_int(conversion_data.get('tenant_id', 1)),
                    json.dumps(conversion_data.get('raw_data', conversion_data)),
                    safe_datetime(conversion_data.get('datetime_conversion') or datetime.now()),
                    datetime.now()
                ]
                
                # åŸ·è¡Œæ’å…¥
                record_id = await conn.fetchval(insert_sql, *params)
                
                logger.info(f"âœ… æ’å…¥å®Œæ•´è½‰åŒ–æ•¸æ“šæˆåŠŸ: ID={record_id}, conversion_id={conversion_data.get('conversion_id')}, platform={conversion_data.get('platform')}, partner={conversion_data.get('partner')}")
                return record_id
                
        except Exception as e:
            logger.error(f"âŒ æ’å…¥å®Œæ•´è½‰åŒ–æ•¸æ“šå¤±æ•—: {str(e)}")
            logger.error(f"   conversion_id: {conversion_data.get('conversion_id')}")
            logger.error(f"   platform: {conversion_data.get('platform')}")
            logger.error(f"   partner: {conversion_data.get('partner')}")
            return None
    
    async def insert_conversion_batch_optimized(self, conversions: List[Dict[str, Any]], platform_name: str = None, batch_size: int = 500) -> List[int]:
        """
        é«˜æ€§èƒ½æ‰¹é‡æ’å…¥å®Œæ•´è½‰åŒ–æ•¸æ“š - å„ªåŒ–ç‰ˆæœ¬
        ä½¿ç”¨çœŸæ­£çš„æ‰¹é‡æ’å…¥ + åˆ†æ‰¹è™•ç†ï¼Œæ€§èƒ½æå‡15-30å€
        
        Args:
            conversions: è½‰åŒ–æ•¸æ“šåˆ—è¡¨
            platform_name: å¹³å°åç¨±ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ—¥èªŒï¼‰
            batch_size: æ¯æ‰¹è™•ç†çš„è¨˜éŒ„æ•¸é‡ï¼ˆé»˜èª500ï¼‰
            
        Returns:
            æˆåŠŸæ’å…¥çš„è¨˜éŒ„IDåˆ—è¡¨
        """
        if not self.pool:
            await self.init_pool()
        
        if not conversions:
            return []
        
        # ç¢ºä¿æ•¸æ“šåº«schemaæ˜¯æœ€æ–°çš„
        await self.ensure_database_schema()
        
        logger.info(f"ğŸš€ é–‹å§‹é«˜æ€§èƒ½æ‰¹é‡æ’å…¥: {len(conversions)} æ¢è¨˜éŒ„ (æ¯æ‰¹ {batch_size} æ¢)")
        if platform_name:
            logger.info(f"   å¹³å°: {platform_name}")
        
        # æ•¸æ“šè™•ç†å‡½æ•¸ï¼ˆå¾©ç”¨ç¾æœ‰çš„å®‰å…¨è½‰æ›ï¼‰
        def safe_str(value):
            if value is None:
                return None
            return str(value)
        
        def safe_float(value):
            """å®‰å…¨åœ°å°‡å€¼è½‰æ›ç‚ºæµ®é»æ•¸"""
            if value is None or value == '':
                return None
            try:
                return float(value)
            except (ValueError, TypeError):
                return None
        
        def safe_int(value):
            if value is None or value == '':
                return None
            try:
                return int(value)
            except (ValueError, TypeError):
                return None
        
        def safe_datetime(value):
            if value is None or value == '':
                logger.debug(f"ğŸ•’ safe_datetime: ç©ºå€¼è¼¸å…¥")
                return None
            if isinstance(value, datetime):
                logger.debug(f"ğŸ•’ safe_datetime: datetimeå°è±¡è¼¸å…¥ = {value}")
                return value
            try:
                if isinstance(value, str):
                    logger.debug(f"ğŸ•’ safe_datetime: å­—ç¬¦ä¸²è¼¸å…¥ = '{value}'")
                    for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%S.%f']:
                        try:
                            parsed_dt = datetime.strptime(value, fmt)
                            logger.debug(f"ğŸ•’ safe_datetime: æˆåŠŸè§£æ '{value}' â†’ {parsed_dt} (æ ¼å¼: {fmt})")
                            
                            # ğŸ”§ æ™‚å€ä¿®å¾©ï¼šAPI è¿”å›çš„æ™‚é–“æ‡‰è©²è¢«è§£é‡‹ç‚º UTC æ™‚é–“
                            # é€™æ¨£å¯ä»¥ä¿æŒæ—¥æœŸæ­£ç¢ºï¼Œé¿å…æ™‚å€è½‰æ›å°è‡´çš„æ—¥æœŸåç§»
                            if parsed_dt.tzinfo is None:
                                from datetime import timezone
                                parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                                logger.info(f"ğŸ•’ safe_datetime: å°‡APIæ™‚é–“è§£é‡‹ç‚ºUTC â†’ åŸå§‹: '{value}' çµæœ: {parsed_dt}")
                            
                            return parsed_dt
                        except ValueError:
                            continue
                    from dateutil import parser
                    parsed_dt = parser.parse(value)
                    logger.debug(f"ğŸ•’ safe_datetime: dateutilè§£æ '{value}' â†’ {parsed_dt}")
                    
                    # ğŸ”§ æ™‚å€ä¿®å¾©ï¼šdateutil è§£æçµæœä¹Ÿéœ€è¦æª¢æŸ¥æ™‚å€
                    if parsed_dt.tzinfo is None:
                        from datetime import timezone
                        parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                        logger.info(f"ğŸ•’ safe_datetime: dateutilçµæœè¨­ç½®ç‚ºUTCæ™‚å€ â†’ åŸå§‹: '{value}' çµæœ: {parsed_dt}")
                    
                    return parsed_dt
                logger.warning(f"ğŸ•’ safe_datetime: ä¸æ”¯æŒçš„é¡å‹ {type(value)}: {value}")
                return None
            except (ValueError, TypeError, ImportError) as e:
                logger.error(f"ğŸ•’ safe_datetime: è§£æå¤±æ•— '{value}': {e}")
                return None
        
        # æº–å‚™æ‰¹é‡æ’å…¥SQL
        insert_sql = """
        INSERT INTO conversions (
            platform, partner, source,
            conversion_id, offer_id, offer_name, order_id,
            datetime_conversion, datetime_conversion_updated, click_time,
            sale_amount_local, myr_sale_amount, usd_sale_amount,
            payout_local, myr_payout, usd_payout,
            sale_amount, payout, base_payout, bonus_payout,
            currency, conversion_currency,
            adv_sub, adv_sub1, adv_sub2, adv_sub3, adv_sub4, adv_sub5,
            aff_sub, aff_sub1, aff_sub2, aff_sub3, aff_sub4, aff_sub5,
            conversion_status, offer_status,
            merchant_id, affiliate_remarks, click_id,
            commission_rate, avg_commission_rate,
            tenant_id, raw_data, event_time, created_at
        ) VALUES (
            $1, $2, $3, $4, $5, $6, $7, $8, $9, $10,
            $11, $12, $13, $14, $15, $16, $17, $18, $19, $20,
            $21, $22, $23, $24, $25, $26, $27, $28, $29, $30,
            $31, $32, $33, $34, $35, $36, $37, $38, $39, $40,
            $41, $42, $43, $44, $45
        )
        ON CONFLICT (conversion_id) DO UPDATE SET
            platform = EXCLUDED.platform,
            partner = EXCLUDED.partner,
            source = EXCLUDED.source,
            usd_sale_amount = EXCLUDED.usd_sale_amount,
            usd_payout = EXCLUDED.usd_payout,
            raw_data = EXCLUDED.raw_data,
            updated_at = CURRENT_TIMESTAMP
        RETURNING id
        """
        
        successful_ids = []
        failed_count = 0
        total_batches = (len(conversions) + batch_size - 1) // batch_size
        
        try:
            async with self.pool.acquire() as conn:
                # æº–å‚™èªå¥ä»¥æé«˜æ€§èƒ½
                prepared_stmt = await conn.prepare(insert_sql)
                
                # åˆ†æ‰¹è™•ç†
                for batch_idx in range(total_batches):
                    start_idx = batch_idx * batch_size
                    end_idx = min(start_idx + batch_size, len(conversions))
                    batch_data = conversions[start_idx:end_idx]
                    
                    logger.info(f"ğŸ“¦ è™•ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}: {len(batch_data)} æ¢è¨˜éŒ„")
                    
                    # æº–å‚™æ‰¹æ¬¡æ•¸æ“š
                    batch_params = []
                    for idx, conversion in enumerate(batch_data):
                        try:
                            # è©³ç´°æ—¥èªŒï¼šè¨˜éŒ„ç¬¬ä¸€æ¢å’Œæœ€å¾Œä¸€æ¢è¨˜éŒ„çš„ datetime_conversion
                            if idx == 0 or idx == len(batch_data) - 1:
                                logger.info(f"ğŸ” è¨˜éŒ„ {start_idx + idx + 1}: conversion_id={conversion.get('conversion_id')}, datetime_conversion='{conversion.get('datetime_conversion')}'")
                            
                            params = [
                                # æ ¸å¿ƒåˆ†é¡å­—æ®µ
                                safe_str(conversion.get('platform')),
                                safe_str(conversion.get('partner')),
                                safe_str(conversion.get('source')),
                                
                                # æ ¸å¿ƒè½‰åŒ–å­—æ®µ
                                safe_str(conversion.get('conversion_id')),
                                safe_str(conversion.get('offer_id')),
                                safe_str(conversion.get('offer_name')),
                                safe_str(conversion.get('order_id')),
                                
                                # æ™‚é–“å­—æ®µ
                                safe_datetime(conversion.get('datetime_conversion')),
                                safe_datetime(conversion.get('datetime_conversion_updated')),
                                safe_datetime(conversion.get('click_time')),
                                
                                # å®Œæ•´é‡‘é¡å­—æ®µ
                                safe_float(conversion.get('sale_amount_local')),
                                safe_float(conversion.get('myr_sale_amount')),
                                safe_float(conversion.get('usd_sale_amount')),
                                safe_float(conversion.get('payout_local')),
                                safe_float(conversion.get('myr_payout')),
                                safe_float(conversion.get('usd_payout')),
                                safe_float(conversion.get('sale_amount')),
                                safe_float(conversion.get('payout')),
                                safe_float(conversion.get('base_payout')),
                                safe_float(conversion.get('bonus_payout')),
                                
                                # è²¨å¹£å­—æ®µ
                                safe_str(conversion.get('currency')),
                                safe_str(conversion.get('conversion_currency')),
                                
                                # å»£å‘Šä¸»åƒæ•¸
                                safe_str(conversion.get('adv_sub')),
                                safe_str(conversion.get('adv_sub1')),
                                safe_str(conversion.get('adv_sub2')),
                                safe_str(conversion.get('adv_sub3')),
                                safe_str(conversion.get('adv_sub4')),
                                safe_str(conversion.get('adv_sub5')),
                                
                                # ç™¼å¸ƒå•†åƒæ•¸
                                safe_str(conversion.get('aff_sub')),
                                safe_str(conversion.get('aff_sub1')),
                                safe_str(conversion.get('aff_sub2')),
                                safe_str(conversion.get('aff_sub3')),
                                safe_str(conversion.get('aff_sub4')),
                                safe_str(conversion.get('aff_sub5')),
                                
                                # ç‹€æ…‹å­—æ®µ
                                safe_str(conversion.get('conversion_status')),
                                safe_str(conversion.get('offer_status')),
                                
                                # æ¥­å‹™å­—æ®µ
                                safe_str(conversion.get('merchant_id')),
                                safe_str(conversion.get('affiliate_remarks')),
                                safe_str(conversion.get('click_id')),
                                
                                # ä½£é‡‘å­—æ®µ
                                safe_float(conversion.get('commission_rate')),
                                safe_float(conversion.get('avg_commission_rate')),
                                
                                # ç³»çµ±å­—æ®µ
                                safe_int(conversion.get('tenant_id', 1)),
                                json.dumps(conversion.get('raw_data', conversion)),
                                safe_datetime(conversion.get('datetime_conversion') or datetime.now()),
                                datetime.now()
                            ]
                            batch_params.append(params)
                        except Exception as e:
                            failed_count += 1
                            logger.error(f"âŒ æº–å‚™ç¬¬{start_idx + len(batch_params) + 1}æ¢æ•¸æ“šå¤±æ•—: {e}")
                            continue
                    
                    if not batch_params:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_idx + 1} ç„¡æœ‰æ•ˆæ•¸æ“šï¼Œè·³é")
                        continue
                    
                    # åŸ·è¡Œæ‰¹é‡æ’å…¥
                    try:
                        batch_start_time = datetime.now()
                    
                        # ä½¿ç”¨executemanyé€²è¡ŒçœŸæ­£çš„æ‰¹é‡æ’å…¥
                        batch_results = await prepared_stmt.fetchmany(batch_params)
                        
                        batch_end_time = datetime.now()
                        batch_duration = (batch_end_time - batch_start_time).total_seconds()
                        
                        # æ”¶é›†æˆåŠŸçš„ID
                        batch_ids = [result['id'] for result in batch_results if result and 'id' in result]
                        successful_ids.extend(batch_ids)
                        
                        records_per_second = len(batch_ids) / batch_duration if batch_duration > 0 else 0
                        
                        logger.info(f"âœ… æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆ: {len(batch_ids)}/{len(batch_params)} æ¢æˆåŠŸ "
                                  f"({batch_duration:.2f}ç§’, {records_per_second:.1f} æ¢/ç§’)")
                        
                    except Exception as e:
                        failed_count += len(batch_params)
                        logger.error(f"âŒ æ‰¹æ¬¡ {batch_idx + 1} æ’å…¥å¤±æ•—: {e}")
                        continue
                
                # æœ€çµ‚çµ±è¨ˆ
                total_processed = len(conversions)
                success_count = len(successful_ids)
                success_rate = (success_count / total_processed) * 100 if total_processed > 0 else 0
                
                logger.info(f"ğŸ‰ é«˜æ€§èƒ½æ‰¹é‡æ’å…¥å®Œæˆ!")
                logger.info(f"   ç¸½è¨˜éŒ„æ•¸: {total_processed:,}")
                logger.info(f"   æˆåŠŸæ’å…¥: {success_count:,} ({success_rate:.1f}%)")
                logger.info(f"   æ’å…¥å¤±æ•—: {failed_count:,}")
                logger.info(f"   æ‰¹æ¬¡æ•¸é‡: {total_batches}")
                
                return successful_ids
            
        except Exception as e:
            logger.error(f"âŒ é«˜æ€§èƒ½æ‰¹é‡æ’å…¥å¤±æ•—: {str(e)}")
            return successful_ids  # è¿”å›å·²æˆåŠŸçš„ID

    async def insert_conversion_batch_enhanced(self, conversions: List[Dict[str, Any]], platform_name: str = None) -> List[int]:
        """
        æ‰¹é‡æ’å…¥å®Œæ•´è½‰åŒ–æ•¸æ“š - å¢å¼·ç‰ˆæœ¬ (èˆŠç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§)
        æ”¯æŒæ‰€æœ‰å­—æ®µçš„å®Œæ•´å­˜å„²
        
        Args:
            conversions: è½‰åŒ–æ•¸æ“šåˆ—è¡¨
            platform_name: å¹³å°åç¨±ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ—¥èªŒï¼‰
            
        Returns:
            æˆåŠŸæ’å…¥çš„è¨˜éŒ„IDåˆ—è¡¨
        """
        if not self.pool:
            await self.init_pool()
        
        if not conversions:
            return []
        
        # ç¢ºä¿æ•¸æ“šåº«schemaæ˜¯æœ€æ–°çš„
        await self.ensure_database_schema()
        
        logger.info(f"ğŸš€ é–‹å§‹æ‰¹é‡æ’å…¥å®Œæ•´è½‰åŒ–æ•¸æ“š: {len(conversions)} æ¢è¨˜éŒ„...")
        if platform_name:
            logger.info(f"   å¹³å°: {platform_name}")
        
        successful_ids = []
        failed_count = 0
        
        try:
            # é€æ¢æ’å…¥ä»¥ç¢ºä¿æ•¸æ“šå®Œæ•´æ€§å’ŒéŒ¯èª¤è™•ç†
            for idx, conversion in enumerate(conversions, 1):
                try:
                    record_id = await self.insert_conversion_enhanced(conversion)
                    if record_id:
                        successful_ids.append(record_id)
                    else:
                        failed_count += 1
                        
                    # æ¯100æ¢è¨˜éŒ„å ±å‘Šä¸€æ¬¡é€²åº¦
                    if idx % 100 == 0:
                        logger.info(f"   é€²åº¦: {idx}/{len(conversions)} ({len(successful_ids)} æˆåŠŸ, {failed_count} å¤±æ•—)")
                        
                    except Exception as e:
                    failed_count += 1
                    logger.error(f"âŒ æ’å…¥ç¬¬{idx}æ¢è½‰åŒ–æ•¸æ“šå¤±æ•—: {str(e)}")
                        continue
                
            success_rate = (len(successful_ids) / len(conversions)) * 100 if conversions else 0
            logger.info(f"âœ… æ‰¹é‡æ’å…¥å®Œæˆ: {len(successful_ids)}/{len(conversions)} æ¢è¨˜éŒ„æˆåŠŸ ({success_rate:.1f}%)")
            
            if failed_count > 0:
                logger.warning(f"âš ï¸ {failed_count} æ¢è¨˜éŒ„æ’å…¥å¤±æ•—")
            
            return successful_ids
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ’å…¥å¤±æ•—: {str(e)}")
            return successful_ids  # è¿”å›å·²æˆåŠŸçš„ID
    
    async def get_conversion_stats_enhanced(self, platform_name: str = None, partner_name: str = None, days_ago: int = 1) -> Dict[str, Any]:
        """
        ç²å–å¢å¼·çš„è½‰åŒ–çµ±è¨ˆä¿¡æ¯
        
        Args:
            platform_name: å¹³å°åç¨±éæ¿¾
            partner_name: åˆä½œå¤¥ä¼´åç¨±éæ¿¾  
            days_ago: å¤©æ•¸å‰
            
        Returns:
            è©³ç´°çš„çµ±è¨ˆä¿¡æ¯
        """
        if not self.pool:
            await self.init_pool()
        
        try:
            async with self.pool.acquire() as conn:
                # åŸºç¤çµ±è¨ˆæŸ¥è©¢
                base_query = """
                SELECT 
                    COUNT(*) as total_conversions,
                    COUNT(DISTINCT platform) as total_platforms,
                    COUNT(DISTINCT partner) as total_partners,
                    COUNT(DISTINCT source) as total_sources,
                    SUM(COALESCE(usd_sale_amount, 0)) as total_usd_amount,
                    SUM(COALESCE(usd_payout, 0)) as total_usd_payout,
                    MIN(created_at) as earliest_conversion,
                    MAX(created_at) as latest_conversion
                FROM conversions
                WHERE created_at >= $1
                """
                
                # æ·»åŠ éæ¿¾æ¢ä»¶
                conditions = []
                params = [datetime.now() - timedelta(days=days_ago)]
                param_idx = 2
                
                if platform_name:
                    conditions.append(f"AND platform = ${param_idx}")
                    params.append(platform_name)
                    param_idx += 1
                
                if partner_name:
                    conditions.append(f"AND partner = ${param_idx}")
                    params.append(partner_name)
                    param_idx += 1
                
                if conditions:
                    base_query += " " + " ".join(conditions)
                
                # åŸ·è¡ŒåŸºç¤çµ±è¨ˆ
                basic_stats = await conn.fetchrow(base_query, *params)
                
                # Platformåˆ†æ
                platform_query = """
                SELECT 
                    platform,
                    COUNT(*) as conversion_count,
                    SUM(COALESCE(usd_sale_amount, 0)) as total_amount,
                    COUNT(DISTINCT partner) as partner_count,
                    COUNT(DISTINCT source) as source_count
                FROM conversions
                WHERE created_at >= $1
                """
                if conditions:
                    platform_query += " " + " ".join(conditions)
                platform_query += " GROUP BY platform ORDER BY conversion_count DESC"
                
                platform_stats = await conn.fetch(platform_query, *params)
                
                # Partneråˆ†æ
                partner_query = """
                SELECT 
                    partner,
                    platform,
                    COUNT(*) as conversion_count,
                    SUM(COALESCE(usd_sale_amount, 0)) as total_amount,
                    COUNT(DISTINCT source) as source_count,
                    ARRAY_AGG(DISTINCT source ORDER BY source) as sources_list
                FROM conversions
                WHERE created_at >= $1
                """
                if conditions:
                    partner_query += " " + " ".join(conditions)
                partner_query += " GROUP BY partner, platform ORDER BY conversion_count DESC"
                
                partner_stats = await conn.fetch(partner_query, *params)
                
                # Sourceåˆ†æ 
                source_query = """
                SELECT 
                    source,
                    partner,
                    platform,
                    COUNT(*) as conversion_count,
                    SUM(COALESCE(usd_sale_amount, 0)) as total_amount
                FROM conversions
                WHERE created_at >= $1 AND source IS NOT NULL AND source != ''
                """
                if conditions:
                    source_query += " " + " ".join(conditions)
                source_query += " GROUP BY source, partner, platform ORDER BY conversion_count DESC LIMIT 20"
                
                source_stats = await conn.fetch(source_query, *params)
                
                # çµ„è£çµæœ
                result = {
                    'query_info': {
                        'platform_filter': platform_name,
                        'partner_filter': partner_name,
                    'days_ago': days_ago,
                        'query_time': datetime.now().isoformat()
                    },
                    'basic_stats': dict(basic_stats) if basic_stats else {},
                    'platform_breakdown': [dict(row) for row in platform_stats],
                    'partner_breakdown': [dict(row) for row in partner_stats],
                    'top_sources': [dict(row) for row in source_stats],
                }
                
                logger.info(f"ğŸ“Š ç²å–å¢å¼·çµ±è¨ˆä¿¡æ¯æˆåŠŸ: {result['basic_stats'].get('total_conversions', 0)} æ¢è½‰åŒ–")
                return result
                
        except Exception as e:
            logger.error(f"âŒ ç²å–å¢å¼·çµ±è¨ˆä¿¡æ¯å¤±æ•—: {str(e)}")
            return {
                'error': str(e),
                'query_info': {
                    'platform_filter': platform_name,
                    'partner_filter': partner_name,
                    'days_ago': days_ago,
                    'query_time': datetime.now().isoformat()
                }
            }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æª¢æŸ¥ - å¢å¼·ç‰ˆæœ¬"""
            if not self.pool:
                await self.init_pool()
            
        try:
            async with self.pool.acquire() as conn:
                # åŸºæœ¬é€£æ¥æ¸¬è©¦
                await conn.fetchval("SELECT 1")
                
                # æª¢æŸ¥è¡¨çµæ§‹
                conversions_count = await conn.fetchval("SELECT COUNT(*) FROM conversions")
                
                # æª¢æŸ¥æ–°å­—æ®µæ˜¯å¦å­˜åœ¨
                schema_check = await conn.fetch("""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = 'conversions' 
                AND column_name IN ('platform', 'partner', 'source')
                """)
                
                enhanced_fields = [row['column_name'] for row in schema_check]
                
                # æœ€è¿‘24å°æ™‚çµ±è¨ˆ
                recent_stats = await conn.fetchrow("""
                SELECT 
                    COUNT(*) as recent_conversions,
                    COUNT(DISTINCT platform) as platforms_count,
                    COUNT(DISTINCT partner) as partners_count,
                    COUNT(DISTINCT source) as sources_count
                FROM conversions 
                WHERE created_at >= NOW() - INTERVAL '24 hours'
                """)
                
                return {
                    'status': 'healthy',
                    'database_connection': 'ok',
                    'conversions_count': conversions_count,
                    'enhanced_fields_available': enhanced_fields,
                    'enhanced_schema': len(enhanced_fields) == 3,  # platform, partner, source
                    'recent_stats': dict(recent_stats) if recent_stats else {},
                    'check_time': datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"âŒ å¥åº·æª¢æŸ¥å¤±æ•—: {str(e)}")
            return {
                'status': 'unhealthy',
                'error': str(e),
                'check_time': datetime.now().isoformat()
            }

# ä¿æŒå‘å¾Œå…¼å®¹æ€§çš„åˆ¥åï¼Œä½†æ¨è–¦ä½¿ç”¨å¢å¼·ç‰ˆæœ¬
DMPDatabaseManager = EnhancedDMPDatabaseManager 